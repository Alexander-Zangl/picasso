#!/usr/bin/env python
"""
    ..__main__.py
    ~~~~~~~~~~~~~~~~

    Picasso command line interface

    :author: Joerg Schnitzbauer, 2015
    :copyright: Copyright (c) 2015 Jungmann Lab, Max Planck Institute of Biochemistry
"""
import os.path


def _link(files, d_max, tolerance):
    import glob
    paths = glob.glob(files)
    if paths:
        from . import io, postprocess
        for path in paths:
            locs, info = io.load_locs(path)
            linked_locs = postprocess.link(locs, info, d_max, tolerance)
            base, ext = os.path.splitext(path)
            link_info = {'Maximum Distance': d_max,
                         'Maximum Transient Dark Time': tolerance,
                         'Generated by': 'Picasso Link'}
            info.append(link_info)
            io.save_locs(base + '_link.hdf5', linked_locs, info)


def _undrift(files, mode, segmentation, display, fromfile):
    import glob
    paths = glob.glob(files)
    if paths:
        from . import io
        from numpy import savetxt
        if fromfile is not None:
            from numpy import genfromtxt
            drift = genfromtxt(fromfile)
            for path in paths:
                locs, info = io.load_locs(path)
                locs.x -= drift[:, 1][locs.frame]
                locs.y -= drift[:, 0][locs.frame]
                undrift_info = {'From File': fromfile,
                                'Generated by': 'Picasso Undrift'}
                info.append(undrift_info)
                base, ext = os.path.splitext(path)
                io.save_locs(base + '_undrift.hdf5', locs, info)
                savetxt(base + '_drift.txt', drift, header='dx\tdy', newline='\r\n')
                if display:
                    import matplotlib.pyplot as plt
                    plt.style.use('ggplot')
                    plt.figure(figsize=(17, 6))
                    plt.suptitle('Estimated drift')
                    plt.subplot(1, 2, 1)
                    plt.plot(drift[:, 1], label='x')
                    plt.plot(drift[:, 0], label='y')
                    plt.legend(loc='best')
                    plt.xlabel('Frame')
                    plt.ylabel('Drift (pixel)')
                    plt.subplot(1, 2, 2)
                    plt.plot(drift[:, 1], drift[:, 0], color=list(plt.rcParams['axes.prop_cycle'])[2]['color'])
                    plt.axis('equal')
                    plt.xlabel('x')
                    plt.ylabel('y')
                    plt.show()
        else:
            from . import postprocess
            for path in paths:
                print('Undrifting file {}'.format(path))
                locs, info = io.load_locs(path)
                movie = None
                if mode == 'std':
                    directory = os.path.dirname(os.path.abspath(path))
                    movie, _ = io.load_movie(os.path.join(directory, info[0]['File']))
                drift, locs = postprocess.undrift(locs, info, segmentation, mode=mode, movie=movie, display=display)
                base, ext = os.path.splitext(path)
                undrift_info = {'Mode': mode,
                                'Display': display,
                                'Generated by': 'Picasso Undrift'}
                if mode in ['render', 'std']:
                    undrift_info['Segmentation'] = segmentation
                info.append(undrift_info)
                io.save_locs(base + '_undrift.hdf5', locs, info)
                savetxt(base + '_drift.txt', drift, header='dx\tdy', newline='\r\n')


def _density(files, radius):
    import glob
    paths = glob.glob(files)
    if paths:
        from . import io, postprocess
        for path in paths:
            locs, info = io.load_locs(path)
            locs = postprocess.compute_local_density(locs, info, radius)
            base, ext = os.path.splitext(path)
            density_info = {'Generated by': 'Picasso Density',
                            'Radius': radius}
            info.append(density_info)
            io.save_locs(base + '_density.hdf5', locs, info)


def _dbscan(files, radius, min_density):
    import glob
    paths = glob.glob(files)
    if paths:
        from . import io, postprocess
        from h5py import File
        for path in paths:
            print('Loading {} ...'.format(path))
            locs, info = io.load_locs(path)
            clusters, locs = postprocess.dbscan(locs, radius, min_density)
            base, ext = os.path.splitext(path)
            dbscan_info = {'Generated by': 'Picasso DBSCAN',
                           'Radius': radius,
                           'Minimum local density': min_density}
            info.append(dbscan_info)
            io.save_locs(base + '_dbscan.hdf5', locs, info)
            with File(base + '_clusters.hdf5', 'w') as clusters_file:
                clusters_file.create_dataset('clusters', data=clusters)


def _dark(files):
    import glob
    paths = glob.glob(files)
    if paths:
        from . import io, postprocess
        for path in paths:
            locs, info = io.load_locs(path)
            locs = postprocess.compute_dark_times(locs)
            base, ext = os.path.splitext(path)
            dbscan_info = {'Generated by': 'Picasso Dark'}
            info.append(dbscan_info)
            io.save_locs(base + '_dark.hdf5', locs, info)


def _std(files):
    import glob
    paths = glob.glob(files)
    if paths:
        from .io import load_raw
        from numpy import std
        from os.path import splitext
        from tifffile import imsave
        for path in paths:
            movie, info = load_raw(path)
            std_image = std(movie, axis=0, dtype='f4')
            base, ext = splitext(path)
            imsave(base + '_std.tif', std_image)


def _align(target, files, display):
    from .io import load_locs, save_locs
    from .postprocess import align
    from os.path import splitext
    locs_infos = [load_locs(_) for _ in files]
    locs = [_[0] for _ in locs_infos]
    infos = [_[1] for _ in locs_infos]
    aligned_locs = align(locs, infos, display=display)
    align_info = {'Generated by': 'Picasso Align',
                  'Files': files}
    for file, locs_, info in zip(files, aligned_locs, infos):
        info.append(align_info)
        base, ext = splitext(file)
        save_locs(base + '_align.hdf5', locs_, info)


def _join(files):
    from .io import load_locs, save_locs
    from os.path import splitext
    from numpy import append
    locs, info = load_locs(files[0])
    join_info = {'Generated by': 'Picasso Join',
                 'Files': [files[0]]}
    for path in files[1:]:
        locs_, info_ = load_locs(path)
        locs = append(locs, locs_)
        join_info['Files'].append(path)
    base, ext = splitext(files[0])
    info.append(join_info)
    locs.sort(kind='mergesort', order='frame')
    save_locs(base + '_join.hdf5', locs, info)


def _groupprops(files):
    import glob
    paths = glob.glob(files)
    if paths:
        from .io import load_locs, save_datasets
        from .postprocess import groupprops
        from os.path import splitext
        for path in paths:
            locs, info = load_locs(path)
            groups = groupprops(locs)
            base, ext = splitext(path)
            save_datasets(base + '_groupprops.hdf5', info, locs=locs, groups=groups)


def _pair_correlation(files, bin_size, r_max):
    from glob import glob
    paths = glob(files)
    if paths:
        from .io import load_locs
        from .postprocess import pair_correlation
        from matplotlib.pyplot import plot, style, show, xlabel, ylabel
        style.use('ggplot')
        for path in paths:
            print('Loading {}...'.format(path))
            locs, info = load_locs(path)
            print('Calculating pair-correlation...')
            bins_lower, pc = pair_correlation(locs, info, bin_size, r_max)
            plot(bins_lower, pc)
            xlabel('r (pixel)')
            ylabel('pair-correlation (pixel^-2)')
            show()


def _localize(args):
    from glob import glob
    from .io import load_movie, save_locs
    from .localize import CONFIG, identify_async, identifications_from_futures, fit_async, locs_from_fits
    from os.path import splitext
    from time import sleep
    paths = glob(args.files)
    for path in paths:
        print('Processing {}'.format(path))
        movie, info = load_movie(path)
        current, futures = identify_async(movie, args.min_net_gradient, args.box)
        n_frames = len(movie)
        while current[0] < n_frames:
            print('Identifying in frame {:,} of {:,}'.format(current[0]+1, n_frames), end='\r')
            sleep(0.2)
        print('Identifying in frame {:,} of {:,}'.format(n_frames, n_frames))
        ids = identifications_from_futures(futures)
        camera = info[0]['Camera']
        sensor = CONFIG['Cameras'][camera]['Sensor']
        camera_info = {'sensor': sensor}
        if sensor == 'EMCCD':
            em = info[0]['Electron Multiplying']
            readmode = info[0]['Readout Mode']
            preamp = info[0]['Pre-Amp Gain']
            camera_info['sensitivity'] = CONFIG['Cameras'][camera]['Sensitivity'][em][readmode][preamp]
            if em:
                camera_info['gain'] = info[0]['EM Real Gain']
            else:
                camera_info['gain'] = 1
            excitation = info[0]['Excitation Wavelength']
            camera_info['qe'] = CONFIG['Cameras'][camera]['Quantum Efficiency'][excitation]
        elif sensor == 'sCMOS':
            readoutrate = info[0]['Readout Rate']
            gain = info[0]['Gain Setting']
            camera_info['sensitivity'] = CONFIG['Cameras'][camera]['Sensitivity'][readoutrate][gain]
            excitation = info[0]['Excitation Wavelength']
            camera_info['qe'] = CONFIG['Cameras'][camera]['Quantum Efficiency'][excitation]
        elif sensor == 'Simulation':
            pass
        current, thetas, CRLBs, likelihoods, iterations = fit_async(movie,
                                                                    camera_info,
                                                                    ids,
                                                                    args.box,
                                                                    args.convergence,
                                                                    args.max_iterations)
        n_spots = len(ids)
        while current[0] < n_spots:
            print('Fitting spot {:,} of {:,}'.format(current[0]+1, n_spots), end='\r')
            sleep(0.2)
        print('Fitting spot {:,} of {:,}'.format(n_spots, n_spots))
        locs = locs_from_fits(ids, thetas, CRLBs, likelihoods, iterations, args.box)
        localize_info = {'Generated by': 'Picasso Localize',
                         'ROI': None,
                         'Box Size': args.box,
                         'Min. Net Gradient': args.min_net_gradient,
                         'Convergence Criterion': args.convergence,
                         'Max. Iterations': args.max_iterations}
        info.append(localize_info)
        base, ext = splitext(path)
        out_path = base + '_locs.hdf5'
        save_locs(out_path, locs, info)


def _render(args):
    from .lib import locs_glob_map
    from .render import render
    from os.path import splitext
    from matplotlib.pyplot import imsave
    from os import startfile
    from .io import load_user_settings, save_user_settings

    def render_many(locs, info, path, oversampling, blur_method, min_blur_width, vmin, vmax, cmap, silent):
        if blur_method == 'none':
            blur_method = None
        N, image = render(locs, info, oversampling, blur_method=blur_method, min_blur_width=min_blur_width)
        base, ext = splitext(path)
        out_path = base + '.png'
        im_max = image.max() / 100
        imsave(out_path, image, vmin=vmin * im_max, vmax=vmax * im_max, cmap=cmap)
        if not silent:
            startfile(out_path)

    settings = load_user_settings()
    cmap = args.cmap
    if cmap is None:
        try:
            cmap = settings['Render']['Colormap']
        except KeyError:
            cmap = 'viridis'
    settings['Render']['Colormap'] = cmap
    save_user_settings(settings)

    locs_glob_map(render_many, args.files, args=(args.oversampling, args.blur_method, args.min_blur_width, args.vmin, args.vmax,
                                                 cmap, args.silent))


def main():
    import argparse

    # Main parser
    parser = argparse.ArgumentParser('picasso')
    subparsers = parser.add_subparsers(dest='command')

    for command in ['toraw', 'localize', 'filter', 'render']:
        subparsers.add_parser(command)

    # link parser
    link_parser = subparsers.add_parser('link', help='link localizations in consecutive frames')
    link_parser.add_argument('files', help='one or multiple hdf5 localization files specified by a unix style path pattern')
    link_parser.add_argument('-d', '--distance', type=float, default=1.0,
                             help='maximum distance between localizations to consider them the same binding event (default=1.0)')
    link_parser.add_argument('-t', '--tolerance', type=int, default=1,
                             help='maximum dark time between localizations to still consider them the same binding event (default=1)')

    # undrift parser
    undrift_parser = subparsers.add_parser('undrift', help='correct localization coordinates for drift')
    undrift_parser.add_argument('files', help='one or multiple hdf5 localization files specified by a unix style path pattern')
    undrift_parser.add_argument('-m', '--mode', default='render', help='"std", "render" or "framepair")')
    undrift_parser.add_argument('-s', '--segmentation', type=float, default=1000,
                                help='the number of frames to be combined for one temporal segment (default=1000)')
    undrift_parser.add_argument('-f', '--fromfile', type=str, help='apply drift from specified file instead of computing it')
    undrift_parser.add_argument('-d', '--nodisplay', action='store_false', help='do not display estimated drift')

    # local density
    density_parser = subparsers.add_parser('density', help='compute the local density of localizations')
    density_parser.add_argument('files', help='one or multiple hdf5 localization files specified by a unix style path pattern')
    density_parser.add_argument('radius', type=float, help='maximal distance between to localizations to be considered local')

    # DBSCAN
    dbscan_parser = subparsers.add_parser('dbscan', help='cluster localizations')
    dbscan_parser.add_argument('files', help='one or multiple hdf5 localization files specified by a unix style path pattern')
    dbscan_parser.add_argument('radius', type=float, help='maximal distance between to localizations to be considered local')
    dbscan_parser.add_argument('density', type=int, help='minimum local density for localizations to be assigned to a cluster')

    # Dark time
    dark_parser = subparsers.add_parser('dark', help='compute the dark time for grouped localizations')
    dark_parser.add_argument('files', help='one or multiple hdf5 localization files specified by a unix style path pattern')

    # STD Image
    std_parser = subparsers.add_parser('std', help='generate the std image of a raw movie')
    std_parser.add_argument('files', help='one or multiple raw files, specified by a unix style path pattern')

    # align
    align_parser = subparsers.add_parser('align', help='align one localization file to another')
    align_parser.add_argument('-d', '--display', help='display correlation', action='store_true')
    # align_parser.add_argument('-a', '--affine', help='include affine transformations (may take long time)', action='store_true')
    align_parser.add_argument('file', help='a localization file', nargs='+')

    # join
    join_parser = subparsers.add_parser('join', help='join hdf5 localization lists')
    join_parser.add_argument('file', nargs='+', help='the hdf5 localization files to be joined')

    # group properties
    groupprops_parser = subparsers.add_parser('groupprops', help='calculate and various properties of localization groups')
    groupprops_parser.add_argument('files', help='one or multiple hdf5 localization files specified by a unix style path pattern')

    # Pair correlation
    pc_parser = subparsers.add_parser('pc', help='calculate the pair-correlation of localizations')
    pc_parser.add_argument('-b', '--binsize', type=float, default=0.1, help='the bin size')
    pc_parser.add_argument('-r', '--rmax', type=float, default=10, help='The maximum distance to calculate the pair-correlation')
    pc_parser.add_argument('files', help='one or multiple hdf5 localization files specified by a unix style path pattern')

    # localize
    localize_parser = subparsers.add_parser('localize', help='identify and fit single molecule spots')
    localize_parser.add_argument('files', nargs='?', help='one or multiple movie files specified by a unix style path pattern')
    localize_parser.add_argument('-b', '--box', type=int, default=7, help='box side length')
    localize_parser.add_argument('-m', '--min-net-gradient', type=float, default=5000, help='minimum net gradient')
    localize_parser.add_argument('-c', '--convergence', type=float, default=0.001, help='convergence criterion')
    localize_parser.add_argument('-i', '--max-iterations', type=int, default=100, help='maximum fit iterations')

    # render
    render_parser = subparsers.add_parser('render', help='render localization based images')
    render_parser.add_argument('files', nargs='?', help='one or multiple localization files specified by a unix style path pattern')
    render_parser.add_argument('-o', '--oversampling', type=float, default=1.0, help='the number of super-resolution pixels per camera pixels')
    render_parser.add_argument('-b', '--blur-method', choices=['none', 'convolve', 'gaussian'], default='convolve')
    render_parser.add_argument('-w', '--min-blur-width', type=float, default=0.0, help='minimum blur width if blur is applied')
    render_parser.add_argument('--vmin', type=float, default=0.0, help='minimum colormap level in range 0-100')
    render_parser.add_argument('--vmax', type=float, default=20.0, help='maximum colormap level in range 0-100')
    render_parser.add_argument('-c', '--cmap', choices=['viridis', 'inferno', 'plasma', 'magma', 'hot', 'gray'], help='the colormap to be applied')
    render_parser.add_argument('-s', '--silent', action='store_true', help='do not open the image file')

    # simulate
    simulate_parser = subparsers.add_parser('simulate', help='simulate DNA-PAINT movies')

    # design
    design_parser = subparsers.add_parser('design', help='design RRO structures')
    # Parse
    args = parser.parse_args()
    if args.command:
        if args.command == 'toraw':
            from .gui import toraw
            toraw.main()
        elif args.command == 'localize':
            if args.files:
                _localize(args)
            else:
                from .gui import localize
                localize.main()
        elif args.command == 'filter':
            from .gui import filter
            filter.main()
        elif args.command == 'render':
            if args.files:
                _render(args)
            else:
                from .gui import render
                render.main()
        elif args.command == 'link':
            _link(args.files, args.distance, args.tolerance)
        elif args.command == 'undrift':
            _undrift(args.files, args.mode, args.segmentation, args.nodisplay, args.fromfile)
        elif args.command == 'density':
            _density(args.files, args.radius)
        elif args.command == 'dbscan':
            _dbscan(args.files, args.radius, args.density)
        elif args.command == 'dark':
            _dark(args.files)
        elif args.command == 'std':
            _std(args.files)
        elif args.command == 'align':
            _align(args.target, args.file, args.display)
        elif args.command == 'join':
            _join(args.file)
        elif args.command == 'groupprops':
            _groupprops(args.files)
        elif args.command == 'pc':
            _pair_correlation(args.files, args.binsize, args.rmax)
        elif args.command == 'simulate':
            from .gui import simulate
            simulate.main()
        elif args.command == 'design':
            from .gui import design
            design.main()
    else:
        parser.print_help()


if __name__ == '__main__':
    main()
